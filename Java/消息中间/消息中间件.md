###  一 消息中间件

>以下为暂时未完成内容
>
>rabbitmq Topic Exchange 主题交换机， Fanout Exchang 扇型交换机，消费者接收到消息的消息确认机制。
>
>kafka 介绍(加入自己理解写)
>
>代码 带回调生产者/自定义分区/事物提交
>
>指定topic、partition、offset消费，以及消息过滤

#### 1. 应用场景

在双十一时，巨量用户抢购一个商品，若同时访问服务器，服务器肯定无法接受。解决办法为将请求的订单信息先写入到消息队列中，然后让服务器订阅该消息队列，从其取信，如果请求数量超过了消息队列的上限，那么消息队列会拒收，所以减小了服务器的压力。



#### 2. 消息中间件解决什么问题

1. 应用解耦 

2. 流量削峰

   要对流量进行削峰，最容易想到的解决方案就是用消息队列来缓冲瞬时流量，把同步的直接调用转换成异步的间接推送，中间通过一个队列在一端承接瞬时的流量洪峰，在另一端平滑地将消息推送出去。

####  2. 消息队列模式

1. 点对点式：

   消息发送消息，消息代理将其放入一个队列中，消息接收者从队列中获取消息内容，消息读取后被移出队列。

   消息只有唯一的发送者和接受者。

   利用消息队列可以解耦生产者和消费者。多个生产者可以向同一个消息队列发送消息。

   但是，一个消息在被一个消息者处理的时候，这个消息在队列上会被锁住或者被移除并且其他消费者无法处理该消息。也就是说一个具体的消息只能由一个消费者消费。

2. 发布订阅式：

   发送者（发布者）发送消息到主题，多个接收者（订阅者）监听（订阅）这个主题，那么就会在消息到达时同时收到消息。

   例如，一个系统中产生的事件可以通过这种模式让发布者通知所有订阅者。在许多队列系统中常常用主题(topics)这个术语指代发布/订阅模式。
   
   在 RabbitMQ 中，主题就是发布/订阅模式的一种具体实现(更准确点说是交换器(exchange)的一种)，
   
   一般来说，订阅有两种类型：
   
   - 临时(ephemeral)订阅，这种订阅只有在消费者启动并且运行的时候才存在。一旦消费者退出，相应的订阅以及尚未处理的消息就会丢失。
   - 持久(durable)订阅，这种订阅会一直存在，除非主动去删除。消费者退出后，消息系统会继续维护该订阅，并且后续消息可以被继续处理。
   
   

### 二 RabbitMQ



#### 1.下载和安装

需要下载rabbitmq，erlang。

1. 在安装`RabbitMQ`之前，首先需要安装`ErLang`包，因为`RabbitMQ`是基于`ErLang`语言的。

2. 下载的`RabbitMQ`安装包和`ErLang`安装包的版本要一致（找到对照表），否则环境会搭建失败，出现很多问题。

3. 官方的下载会很缓慢，可以找找国内的镜像

   

#### 2.消息队列的说明

![image-20210716101755580](C:\Users\12980\Pictures\typora图片\image-20210716101755580.png)

1. 第一个`msg`是要发送的消息；

2. `exchange.direct`是交换机，`direct`模式的交换机，它会规定一个`Routing Key`，如果队列的`Routing Key`和交换机指定的`Routing Key`一样，那么会把消息发送给该队列，对不上号的肯定就不会发送了。

3. `exchange.fanout`也是交换机，`fanout`模式的交换机，它不会规定`Routing Key`，类似广播模式，该交换机将发送消息到每一个队列中去。

4. 中间绿色的当然是四个队列了。

5. `exchange.topic`负责从队列中取信息，它和队列的关系和交换机和队列的关系很像，都是相互绑定，但是不同的是，交换机是发送，而它是接收。

6. China.#和*.news是模糊匹配原则，绑定可以模糊匹配，可以对应多个队列。

   

#### 3.项目集成

##### 3.1 管控台操作组件

>web页面可参考 [管理控制台](https://blog.csdn.net/qq_41097820/article/details/88793329)

##### 3.2 spring 集成 	

>完整项目代码 [代码](https://gitee.com/librety/rabbitmq_springboot.git)

1. 配置文件

   pom.xml

   ~~~
   <!--rabbitmq-->
   <dependency>
   <groupId>org.springframework.boot</groupId>
   <artifactId>spring-boot-starter-amqp</artifactId>
   </dependency>
   <dependency>
   <groupId>org.springframework.boot</groupId>
   <artifactId>spring-boot-starter-web</artifactId>
   </dependency>
   ~~~

   application.yml

   ~~~
   server:
     port: 8021
   spring:
     #给项目来个名字
     application:
       name: rabbitmq-provider
     #配置rabbitMq 服务器
     rabbitmq:
       host: 127.0.0.1
       port: 5672
       username: guest
       password: guest
       #虚拟host 可以不设置,使用server默认host
       #virtual-host: JCcccHost
   ~~~

   

2. 生产者

   队列和交换机持久化以及连接使用设置

   ~~~
       //队列 起名：TestDirectQueue
       @Bean
       public Queue TestDirectQueue() {
           // durable:是否持久化,默认是false,持久化队列：会被存储在磁盘上，当消息代理重启时仍然存在，暂存队列：当前连接有效
           // exclusive:默认也是false，只能被当前创建的连接使用，而且当连接关闭后队列即被删除。此参考优先级高于durable
           // autoDelete:是否自动删除，当没有生产者或者消费者使用此队列，该队列会自动删除。
           //   return new Queue("TestDirectQueue",true,true,false);
    
           //一般设置一下队列的持久化就好,其余两个就是默认false
           return new Queue("TestDirectQueue",true);
       } 
       //Direct交换机 起名：TestDirectExchange
       @Bean
       DirectExchange TestDirectExchange() {
         //  return new DirectExchange("TestDirectExchange",true,true);
           return new DirectExchange("TestDirectExchange",true,false);
       } 
       //绑定  将队列和交换机绑定, 并设置用于匹配键：TestDirectRouting
       @Bean
       Binding bindingDirect() {
           return BindingBuilder.bind(TestDirectQueue()).to(TestDirectExchange()).with("TestDirectRouting");
       } 
       @Bean
       DirectExchange lonelyDirectExchange() {
           return new DirectExchange("lonelyDirectExchange");
       }
   ~~~

   简单的接口进行消息推送

   ~~~
       @Autowired
       RabbitTemplate rabbitTemplate;  //使用RabbitTemplate,这提供了接收/发送等等方法
    
       @GetMapping("/sendDirectMessage")
       public String sendDirectMessage() {
           String messageId = String.valueOf(UUID.randomUUID());
           String messageData = "test message, hello!";
           String createTime = LocalDateTime.now().format(DateTimeFormatter.ofPattern("yyyy-MM-dd HH:mm:ss"));
           Map<String,Object> map=new HashMap<>();
           map.put("messageId",messageId);
           map.put("messageData",messageData);
           map.put("createTime",createTime);
           //将消息携带绑定键值：TestDirectRouting 发送到交换机TestDirectExchange
           rabbitTemplate.convertAndSend("TestDirectExchange", "TestDirectRouting", map);
           return "ok";
       }
   ~~~

   

3. 消费者

   可以不设置，直接建后面的监听，使用注解来让监听器监听对应的队列也可以，*配置上了的话，其实消费者也是生成者的身份，也能推送该消息

   ~~~
   //队列 起名：TestDirectQueue
       @Bean
       public Queue TestDirectQueue() {
           return new Queue("TestDirectQueue",true);
       } 
       //Direct交换机 起名：TestDirectExchange
       @Bean
       DirectExchange TestDirectExchange() {
           return new DirectExchange("TestDirectExchange");
       } 
       //绑定  将队列和交换机绑定, 并设置用于匹配键：TestDirectRouting
       @Bean
       Binding bindingDirect() {
           return BindingBuilder.bind(TestDirectQueue()).to(TestDirectExchange()).with("TestDirectRouting");
       }
   ~~~

   创建消息接收监听

   ~~~
   @RabbitHandler
       public void process(Map testMessage) {
           System.out.println("DirectReceiver消费者收到消息  : " + testMessage.toString());
       }
   ~~~

4. 序列化

   ~~~
    @Bean
       public Jackson2JsonMessageConverter messageConverter() {
           return new Jackson2JsonMessageConverter();
       }
   ~~~

### 三 kafak 

#### 1.项目集成

##### 1.1 管控台操作组件

>待补充

##### 3.2 spring 集成 	

>

1. 配置文件

   pom.xml

   ~~~
   <dependency>
       <groupId>org.springframework.kafka</groupId>
       <artifactId>spring-kafka</artifactId>
   </dependency>
   ~~~

   application.yml

   ~~~
   ###########【Kafka集群】###########
   spring.kafka.bootstrap-servers=112.126.74.249:9092,112.126.74.249:9093
   ###########【初始化生产者配置】###########
   # 重试次数
   spring.kafka.producer.retries=0
   # 应答级别:多少个分区副本备份完成时向生产者发送ack确认(可选0、1、all/-1)
   spring.kafka.producer.acks=1
   # 批量大小
   spring.kafka.producer.batch-size=16384
   # 提交延时
   spring.kafka.producer.properties.linger.ms=0
   # 当生产端积累的消息达到batch-size或接收到消息linger.ms后,生产者就会将消息提交给kafka
   # linger.ms为0表示每接收到一条消息就提交给kafka,这时候batch-size其实就没用了
   ​
   # 生产端缓冲区大小
   spring.kafka.producer.buffer-memory = 33554432
   # Kafka提供的序列化和反序列化类
   spring.kafka.producer.key-serializer=org.apache.kafka.common.serialization.StringSerializer
   spring.kafka.producer.value-serializer=org.apache.kafka.common.serialization.StringSerializer
   # 自定义分区器
   # spring.kafka.producer.properties.partitioner.class=com.felix.kafka.producer.CustomizePartitioner
   ​
   ###########【初始化消费者配置】###########
   # 默认的消费组ID
   spring.kafka.consumer.properties.group.id=defaultConsumerGroup
   # 是否自动提交offset
   spring.kafka.consumer.enable-auto-commit=true
   # 提交offset延时(接收到消息后多久提交offset)
   spring.kafka.consumer.auto.commit.interval.ms=1000
   # 当kafka中没有初始offset或offset超出范围时将自动重置offset
   # earliest:重置为分区中最小的offset;
   # latest:重置为分区中最新的offset(消费分区中新产生的数据);
   # none:只要有一个分区不存在已提交的offset,就抛出异常;
   spring.kafka.consumer.auto-offset-reset=latest
   # 消费会话超时时间(超过这个时间consumer没有发送心跳,就会触发rebalance操作)
   spring.kafka.consumer.properties.session.timeout.ms=120000
   # 消费请求超时时间
   spring.kafka.consumer.properties.request.timeout.ms=180000
   # Kafka提供的序列化和反序列化类
   spring.kafka.consumer.key-deserializer=org.apache.kafka.common.serialization.StringDeserializer
   spring.kafka.consumer.value-deserializer=org.apache.kafka.common.serialization.StringDeserializer
   # 消费端监听的topic不存在时，项目启动会报错(关掉)
   spring.kafka.listener.missing-topics-fatal=false
   # 设置批量消费
   # spring.kafka.listener.type=batch
   # 批量消费每次最多消费多少条消息
   # spring.kafka.consumer.max-poll-records=50
   ~~~

   

2. 生产者

   队列和交换机持久化以及连接使用设置

   ~~~
   @RestController
   public class KafkaProducer {
       @Autowired
       private KafkaTemplate<String, Object> kafkaTemplate;
   ​
       // 发送消息
       @GetMapping("/kafka/normal/{message}")
       public void sendMessage1(@PathVariable("message") String normalMessage) {
           kafkaTemplate.send("topic1", normalMessage);
       }
   }
   ~~~

3. 消费者

   ~~~
   @Component
   public class KafkaConsumer {
       // 消费监听
       @KafkaListener(topics = {"topic1"})
       public void onMessage1(ConsumerRecord<?, ?> record){
           // 消费的哪个topic、partition的消息,打印出消息内容
           System.out.println("简单消费："+record.topic()+"-"+record.partition()+"-"+record.value());
       }
   }
   ~~~

4. 带回调生产者/自定义分区/事物提交

   指定topic、partition、offset消费，以及消息过滤

   **待补充**

### 四 RabbitMQ 和 Kafka 的技术对比

1. 结论 

   kafka适合数据量大的场景，rabbitmq适合可靠，对速度要求(吞吐量)不高的场景。

2. 举例 

   在实际生产应用中，通常会使用kafka作为消息传输的数据管道，rabbitmq作为交易数据作为数据传输管道，主要的取舍因素则是是否存在丢数据的可能；rabbitmq在金融场景中经常使用，具有较高的严谨性，数据丢失的可能性更小，同事具备更高的实时性；而kafka优势主要体现在吞吐量上，虽然可以通过策略实现数据不丢失，但从严谨性角度来讲，大不如rabbitmq；而且由于kafka保证每条消息最少送达一次，有较小的概率会出现数据重复发送的情况；

#### 1.在应用场景方面

 **RabbitMQ**
 在实时的对可靠性要求比较高的消息传递上，适合企业级的消息发送订阅。
 **kafka**
 主要用于处理活跃的流式数据,大数据量的数据处理上。常用日志采集，数据采集上。

#### 2.架构模型方面

 **RabbitMQ**
 RabbitMQ遵循AMQP协议，RabbitMQ的broker由Exchange,Binding,queue组成，其中exchange和binding组成了消息的路由键；客户端Producer通过连接channel和server进行通信，Consumer从queue获取消息进行消费（长连接，queue有消息会推送到consumer端，consumer循环从输入流读取数据）。rabbitMQ以broker为中心；有消息的确认机制。
 **kafka**
 kafka遵从一般的MQ结构，producer，broker，consumer，以consumer为中心，消息的消费信息保存的客户端consumer上，consumer根据消费的点，从broker上批量pull数据；无消息确认机制。

 #### 3.吞吐量

 **kafka**
 kafka具有高的吞吐量，内部采用消息的批量处理，zero-copy机制，数据的存储和获取是本地磁盘顺序批量操作，具有O(1)的复杂度，消息处理的效率很高。
 **rabbitMQ**
 rabbitMQ在吞吐量方面稍逊于kafka，他们的出发点不一样，rabbitMQ支持对消息的可靠的传递，支持事务，不支持批量的操作；基于存储的可靠性的要求存储可以采用内存或者硬盘。

#### 4. 可用性方面

 **rabbitMQ**
 rabbitMQ支持miror的queue，主queue失效，miror queue接管。
 **kafka**
 kafka的broker支持主备模式。

 #### 5.集群负载均衡方面

 **kafka**
 kafka采用zookeeper对集群中的broker、consumer进行管理，可以注册topic到zookeeper上；通过zookeeper的协调机制，producer保存对应topic的broker信息，可以随机或者轮询发送到broker上；并且producer可以基于语义指定分片，消息发送到broker的某分片上。
 **rabbitMQ**
 rabbitMQ的负载均衡需要单独的loadbalancer进行支持。
